{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment=None\n",
    "import tsfresh\n",
    "from dtaidistance import dtw\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def  hampel(data,k=5,t0=3):\n",
    " #1判断长度问题\n",
    "    if len(data) == 0:\n",
    "        print('长度为0')\n",
    "        return False\n",
    "    data = data.loc[:,['TimeStr', 'Ia']]\n",
    "    data.loc[:,'TimeStr'] = pd.to_datetime(data['TimeStr'])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    #1删除重复值\n",
    "    data.loc[:,'TimeStr']=pd.to_datetime(data['TimeStr'].apply(lambda x: datetime.strftime(x, format='%Y-%m-%d %H:%M:%S')))\n",
    "    data.drop_duplicates('TimeStr', inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "     #2补全时间 \n",
    "    time_series = pd.date_range(data[\"TimeStr\"].min(), data[\"TimeStr\"].max(), freq='s')\n",
    "    ts = pd.DataFrame(time_series, columns=[\"time\"])\n",
    "    data = data.merge(ts, how='right', left_on=\"TimeStr\", right_on=\"time\")\n",
    "    data.drop(['TimeStr'], axis=1, inplace=True)\n",
    "    data.sort_values(by='time', inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    Ia = data['Ia']\n",
    "    #3Hampel Filter\n",
    "    L = 1.4826\n",
    "    rolling_median=Ia.rolling(window=k,min_periods=1,center=True).median()\n",
    "    difference=np.abs(rolling_median-Ia)\n",
    "    median_abs_deviation=difference.rolling(window=k,min_periods=1,center=False).median()\n",
    "    threshold=t0*L*median_abs_deviation\n",
    "    outlier_idx=difference>threshold\n",
    "    Ia[outlier_idx]=rolling_median[outlier_idx]\n",
    "    #4补缺失值\n",
    "    Ia.fillna(0,inplace=True)  #check\n",
    "    if len(Ia) == 86401:\n",
    "        return Ia\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def mkdir_plot(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.mkdir(path)\n",
    "        return True\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature(object):\n",
    "    def __init__(self,Ia,l):\n",
    "        self.l=l\n",
    "        self.max_window=60*30\n",
    "        self.len_window=60*l \n",
    "        self.interval=60\n",
    "#         self.data=hampel(data)\n",
    "        self.data = Ia.copy()\n",
    "        self.y={}\n",
    "        self.matrix_length=int((len(self.data)-self.max_window)/self.interval)+1 #特征向量的行数 或 窗口的总个数\n",
    "        self.featue_matrix=pd.DataFrame({'window_no':range(self.matrix_length)})\n",
    "\n",
    "        #self.y 字典 ：存储所有滑窗的y\n",
    "    def data_process(self):\n",
    "        for i in range(self.matrix_length):\n",
    "#             self.data_y.setdefault(i)\n",
    "            self.y.setdefault(i)\n",
    "            idx_start=i*self.interval\n",
    "            idx_end=idx_start + self.len_window\n",
    "            if type(self.data) == pd.Series:\n",
    "                self.y[i]=self.data[idx_start:idx_end].reset_index(drop=True)\n",
    "\n",
    "        return self\n",
    "        #遍历self.y 计算对应的特征向量\n",
    "    \n",
    "    def raw_y(self):\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(self.y[i][0])\n",
    "        self.featue_matrix['raw_y_%s' % self.l]=res_l\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def longest_strike_above_mean(self):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.longest_strike_above_mean\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i].reset_index(drop=True)))\n",
    "        self.featue_matrix['longest_strike_above_mean_%s' % self.l]=res_l\n",
    "        \n",
    "        return self\n",
    "        \n",
    "\n",
    "    def sum_values(self):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.sum_values\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['sum_values_%s' % self.l]=res_l\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def ratio_beyond_r_sigma(self,r=3):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.ratio_beyond_r_sigma\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],r))\n",
    "        self.featue_matrix['ratio_beyond_r_sigma_%s' % self.l]=res_l\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def absolute_sum_of_changes(self,r=0.3):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.absolute_sum_of_changes\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['absolute_sum_of_changes_%s' % self.l]=res_l\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def mean_second_derivative_central(self):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.mean_second_derivative_central\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['mean_second_derivative_central_%s' % self.l]=res_l\n",
    "          \n",
    "        return self\n",
    "    \n",
    "    def mean_(self):\n",
    "        f=np.mean\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['mean_%s' % self.l]=res_l\n",
    "        return self\n",
    "\n",
    "    def quantile_25(self,q=0.25):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.quantile\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],q))\n",
    "        self.featue_matrix['quantile_25_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def quantile_75(self,q=0.75):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.quantile\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],q))\n",
    "        self.featue_matrix['quantile_75_%s' % self.l]=res_l\n",
    "        return self\n",
    "        \n",
    "    def variance(self):\n",
    "        f=tsfresh.feature_extraction.feature_calculators.variance\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['variance_%s' % self.l]=res_l\n",
    "        return self\n",
    "  \n",
    "    def linear_trend(self):\n",
    "        param = [{\"attr\":\"slope\"}]\n",
    "        f = tsfresh.feature_extraction.feature_calculators.linear_trend\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],param)[0][1])\n",
    "        self.featue_matrix['linear_trend_%s' % self.l]=res_l\n",
    "        return self\n",
    "\n",
    "    def median_(self):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.median\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['median_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def kurtosis(self):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.kurtosis\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['kurtosis_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def maximum(self):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.maximum\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['maximum_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def range_count_8(self,min=0.0001,max=8):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.range_count\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],min,max))\n",
    "        self.featue_matrix['range_count_8_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def range_count_20(self,min=8.0001,max=20):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.range_count\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],min,max))\n",
    "        self.featue_matrix['range_count_20_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def range_count_50(self,min=20.0001,max=50):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.range_count\n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i],min,max))\n",
    "        self.featue_matrix['range_count_50_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def percentage_of_reoccurring_datapoints_to_all_datapoints(self):\n",
    "        f = tsfresh.feature_extraction.feature_calculators.percentage_of_reoccurring_datapoints_to_all_datapoints  \n",
    "        res_l=[]\n",
    "        for i in range(self.matrix_length):\n",
    "            res_l.append(f(self.y[i]))\n",
    "        self.featue_matrix['percentage_of_reoccurring_datapoints_to_all_datapoints_%s' % self.l]=res_l\n",
    "        return self\n",
    "    \n",
    "    def standardscaler(self): #不包括dtw  输出所有的特征列，忽略第一列索引列\n",
    "        f=StandardScaler()\n",
    "        out=f.fit_transform(self.featue_matrix.iloc[:,1:])\n",
    "        \n",
    "        return out\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_case(Ia,l):\n",
    "    '''\n",
    "    输入数据data window长度l\n",
    "    输出特征矩阵 nrow=l,ncol=特征个数\n",
    "    '''\n",
    "    case=feature(Ia,l)  #默认取 5 10 20 30分钟 四种滑窗 \n",
    "    case.data_process()\n",
    "    case.raw_y()\n",
    "    case.longest_strike_above_mean()\n",
    "    case.sum_values()\n",
    "    case.ratio_beyond_r_sigma() #异常点\n",
    "    case.absolute_sum_of_changes()\n",
    "    case.mean_second_derivative_central()\n",
    "    case.mean_()\n",
    "    case.quantile_25()\n",
    "    case.quantile_75()\n",
    "    case.variance()\n",
    "    case.linear_trend()\n",
    "    case.median_()\n",
    "    case.kurtosis()\n",
    "    case.maximum()  \n",
    "    case.range_count_8()\n",
    "    case.range_count_20()\n",
    "    case.range_count_50()\n",
    "    case.percentage_of_reoccurring_datapoints_to_all_datapoints()\n",
    "    \n",
    "    return case.featue_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(cur_Ia,class_name,uuid):\n",
    "    feature_5=construct_case(cur_Ia,5)\n",
    "    print('start to make feature_5')\n",
    "    feature_10 = construct_case(cur_Ia,10)\n",
    "    print('start to make feature_10')\n",
    "    feature_20 = construct_case(cur_Ia,20)\n",
    "    print('start to make feature_20')\n",
    "    feature_30 = construct_case(cur_Ia,30)\n",
    "    print('start to make feature_30')\n",
    "#     feature_5.to_pickle('/home/wrj/FeatureDT/result/%s_%s_feature_5.pkl' % (class_name,uuid))\n",
    "#     feature_10.to_pickle('/home/wrj/FeatureDT/result/%s_%s_feature_10.pkl' % (class_name,uuid))\n",
    "#     feature_20.to_pickle('/home/wrj/FeatureDT/result/%s_%s_feature_30.pkl' % (class_name,uuid))\n",
    "#     feature_30.to_pickle('/home/wrj/FeatureDT/result/%s_%s_feature_60.pkl' % (class_name,uuid))\n",
    "    \n",
    "    return feature_5,feature_10,feature_20,feature_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_result(feature_5,feature_10,feature_20,feature_30,datatype,machine,uuid):\n",
    "    variable_datasets = ['除尘器', '火焰切割机', '电源',  '主机', '激光切割机']\n",
    "    y_label_dict = {'除尘器':1, '火焰切割机':2, '电源':3,  '主机':4, '激光切割机':5}\n",
    "    data_merge = pd.concat((feature_5,feature_10,feature_20,feature_30),axis=1)\n",
    "    data_merge.dropna(inplace=True)\n",
    "    cur_label = y_label_dict[machine]\n",
    "    data_merge['label'] = np.array([cur_label]*len(data_merge))\n",
    "    data_merge.drop([\"raw_y_10\",\"raw_y_20\",\"raw_y_30\"],axis=1,inplace=True )\n",
    "    data_merge.drop(['window_no'],axis=1,inplace=True)\n",
    "    data_merge.to_pickle('/home/wrj/FeatureDT/result/%s/%s_%s_merge.pkl' % (datatype,machine,uuid))\n",
    "    print(\"merge已经写入目标地址\")\n",
    "    print(\"data_merge shape :\",data_merge.shape)\n",
    "    \n",
    "    return data_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_feature_matrix(datatype):\n",
    "    path = r'/home/wrj/FeatureDT/%s' % datatype\n",
    "    variable_datasets = ['除尘器', '火焰切割机', '电源',  '主机', '激光切割机']\n",
    "    y_label_dict = {'除尘器':1, '火焰切割机':2, '电源':3,  '主机':4, '激光切割机':5}\n",
    "    uid_list = []\n",
    "    machine_list = []\n",
    "    for machine in variable_datasets:\n",
    "        read_path = os.path.join(path,machine)\n",
    "        variable_file = os.listdir(read_path)\n",
    "    #     print(variable_file)\n",
    "        for i,file in enumerate(variable_file):\n",
    "            file_path = os.path.join(read_path,file)\n",
    "            print(i,file_path)\n",
    "            uuid = file[0:-4]\n",
    "            uid_list.append(uuid)\n",
    "            machine_list.append(machine)\n",
    "            cur_data = pd.read_csv(file_path)\n",
    "            cur_Ia = hampel(cur_data)\n",
    "            if type(cur_Ia) is not bool:\n",
    "                feature_5,feature_10,feature_20,feature_30 = get_result(cur_Ia,machine,uuid)\n",
    "                data_merge = merge_result(feature_5,feature_10,feature_20,feature_30,datatype,machine,uuid)\n",
    "            else:\n",
    "                print(\"数据有问题\")\n",
    "    return feature_5,feature_10,feature_20,feature_30,data_merge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_data(datatype):\n",
    "    path = '/home/wrj/FeatureDT/result/%s' % datatype\n",
    "    merge_list = os.listdir(path)\n",
    "    for i in range(len(merge_list)):\n",
    "        read_merge_file = os.path.join(path,merge_list[i])\n",
    "        print(i,read_merge_file)\n",
    "        if i == 0:\n",
    "            cur_data_0 = pd.read_pickle(read_merge_file)\n",
    "        elif i == 1:\n",
    "            cur_data_1 = pd.read_pickle(read_merge_file)\n",
    "            temp_data = pd.concat((cur_data_0,cur_data_1),axis = 0)\n",
    "        else:\n",
    "            cur_data = pd.read_pickle(read_merge_file)\n",
    "            temp_data = pd.concat((temp_data,cur_data),axis = 0)\n",
    "    temp_data.reset_index(drop=True,inplace=True)\n",
    "    temp_data.to_pickle('/home/wrj/FeatureDT/model/data/temp_%s.pkl' % datatype)\n",
    "    \n",
    "    return temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_5,feature_10,feature_20,feature_30,data_merge = get_feature_matrix(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_5,feature_10,feature_20,feature_30,data_merge = get_feature_matrix(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = acquire_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = acquire_data(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
